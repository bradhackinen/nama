{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NAMA Demo"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First lets create some simple data and install packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'nama'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mpandas\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mpd\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mnama\u001b[39;00m\n\u001b[1;32m      4\u001b[0m df1 \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mDataFrame([\u001b[39m'\u001b[39m\u001b[39mABC Inc.\u001b[39m\u001b[39m'\u001b[39m,\u001b[39m'\u001b[39m\u001b[39mabc inc\u001b[39m\u001b[39m'\u001b[39m,\u001b[39m'\u001b[39m\u001b[39mA.B.C. INCORPORATED\u001b[39m\u001b[39m'\u001b[39m,\u001b[39m'\u001b[39m\u001b[39mThe XYZ Company\u001b[39m\u001b[39m'\u001b[39m,\u001b[39m'\u001b[39m\u001b[39mX Y Z CO\u001b[39m\u001b[39m'\u001b[39m],columns\u001b[39m=\u001b[39m[\u001b[39m'\u001b[39m\u001b[39mname\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[1;32m      5\u001b[0m df2 \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mDataFrame([\u001b[39m'\u001b[39m\u001b[39mABC Inc.\u001b[39m\u001b[39m'\u001b[39m,\u001b[39m'\u001b[39m\u001b[39mXYZ Co.\u001b[39m\u001b[39m'\u001b[39m],columns\u001b[39m=\u001b[39m[\u001b[39m'\u001b[39m\u001b[39mname\u001b[39m\u001b[39m'\u001b[39m])\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'nama'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import nama\n",
    "\n",
    "df1 = pd.DataFrame(['ABC Inc.','abc inc','A.B.C. INCORPORATED','The XYZ Company','X Y Z CO'],columns=['name'])\n",
    "df2 = pd.DataFrame(['ABC Inc.','XYZ Co.'],columns=['name'])\n",
    "\n",
    "print(f'Toy data:\\ndf1=\\n{df1}\\ndf2=\\n{df2}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nama is built around an object called a `Matcher`, which holds matching information about a set of strings and partitions the strings into non-overlapping groups.\n",
    "   - Strings in the same group are considered \"matched\"\n",
    "   - Strings in different groups are not matched.\n",
    "Nama provides tools for creating, modifying, saving, and loading matchers. Then matchers can be used to generate unique group ids for a set of strings, or perform two-way merges between pandas dataframes according to the match groups."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We start matching by creating an empty matcher\n",
    "matcher = nama.Matcher()\n",
    "\n",
    "# First we need to add all the strings we want to match to the matcher\n",
    "# (in this case the strings the name column of each dataframe)\n",
    "matcher = matcher.add_strings(df1['name'])\n",
    "matcher = matcher.add_strings(df2['name'])\n",
    "\n",
    "# Initially, strings are automatically assigned to singleton groups\n",
    "# (Groups are automatically labelled according to the most common string,\n",
    "# with ties broken alphabetically)\n",
    "print(f'Initial string groups:\\n{matcher.groups}')\n",
    "\n",
    "# At this point we can merge on exact matches, but there isn't much point\n",
    "# (equivalent to pandas merge function)\n",
    "print(f\"Exact matching with singleton groups:\\n{matcher.merge_dfs(df1,df2,on='name')}\")\n",
    "\n",
    "# To get better results, we need to modify the matcher.\n",
    "# Unite merges all groups that contain the passed strings.\n",
    "matcher = matcher.unite(['X Y Z CO','XYZ Co.'])\n",
    "print(f'Updated string groups:\\n{matcher.groups}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`unite` is very flexible. We can pass a single set of strings, a nested list of strings, or mapping from strings to group labels. The mapping can even be a function that evaluates strings and generates a label.This makes it very simple to do hash collision matching.\n",
    "\n",
    "Hash collision matching works by matching any strings that have the same hash. A hash could be almost anything, but one useful way to do collision matching is to match strings that are identical after simplifying both strings.\n",
    "\n",
    "Nama provides some useful simplification functions in nama.utils. `simplify_corp` strips punctuation and capitalization, and removes common parts of names like starting with \"the\", or ending with \"inc\" or \"ltd\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nama.utils import simplify_corp\n",
    "\n",
    "# Make a new matcher for comparison\n",
    "corp_matcher = nama.Matcher(matcher.strings())\n",
    "\n",
    "# Unite strings with the same simplified representation\n",
    "corp_matcher = corp_matcher.unite(simplify_corp)\n",
    "\n",
    "print(f'Groups after uniting by simplify_corp:\\n{corp_matcher.groups}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another useful approach to matching is to construct a similarity measure between strings. The standard way to do this is to break strings into \"tokens\"(words or short substrings) and use a measure like a weighted jaccard similarity index to summarize the overlap between the tokens in pairs ofstrings. The token_similarity module provides tools for matching based on token similarity.\n",
    "\n",
    "First, create a TokenSimilarity model. This can be customized with different tokenizers, similarity measures, and token weighting methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nama.token_similarity import TokenSimilarity\n",
    "\n",
    "token_model = TokenSimilarity()\n",
    "\n",
    "# In the future: A training set can be used to automatically pick the optimal similarity threshold for uniting strings.\n",
    "# For now: Just set the threshold manually.\n",
    "\n",
    "# Then we can use the similarity model to predict matches between the matcher\n",
    "# strings. The predict method returns a new matcher.\n",
    "token_matcher = token_model.predict(matcher.strings(),threshold=0.05)\n",
    "\n",
    "\n",
    "# The nama.plot() function can help visualize the how strings are grouped the matchers\n",
    "\n",
    "nama.plot(token_matcher,matcher.strings(),matcher_names=['corp_matcher','token_matcher'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also train an Embedding Similarity Model to predict the similarity of larger and more complex groupings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nama.embedding_similarity import EmbeddingSimilarityModel\n",
    "\n",
    "train_kwargs = {\n",
    "    'max_epochs': 2,\n",
    "    'warmup_frac': 0.2,\n",
    "    'transformer_lr':1e-5,\n",
    "    'score_lr':10,\n",
    "    'batch_size':8,\n",
    "}\n",
    "\n",
    "sim = EmbeddingSimilarityModel()\n",
    "\n",
    "# Due the number of examples in our matcher the model will not be able to learn the similarities, the model will attempt nonetheless\n",
    "history_df = sim.train(matcher, verbose=True, **train_kwargs)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `nama.plot()` function can also help visualize the how strings are grouped in multiple matchers at the same time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nama.plot([corp_matcher,token_matcher], matcher.strings(), matcher_names=['corp_matcher','token_matcher'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that the combination of the two matchers correctly groups all the strings. It is often useful to combine multiple matching techniques.\n",
    "\n",
    "We can integrate the corp and token matchers into the original matcher with unite."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matcher = matcher.unite(corp_matcher)\n",
    "matcher = matcher.unite(token_matcher)\n",
    "\n",
    "nama.plot(matcher, matcher.strings())\n",
    "\n",
    "# Now merging the dataframes gives us the desired output\n",
    "print(f\"Merging with the final matcher:\\n{matcher.merge_dfs(df1,df2,on='name')}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The matcher can also be converted to a dataframe if we want to cluster the names in one dataset or create a mapping to string groups that can be used accross multiple datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "matcher_df = matcher.to_df()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we can save the matcher in csv format for later use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matcher.to_csv('matcher.csv')\n",
    "\n",
    "# ...and load it again at a later time\n",
    "\n",
    "loaded_matcher = nama.read_csv('matcher.csv')\n",
    "\n",
    "# Visually verify that the saved and loaded matchers are the same\n",
    "nama.plot([matcher,loaded_matcher],matcher.strings(),matcher_names=['saved','loaded'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
