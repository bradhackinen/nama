{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NAMA Demo"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First lets create some simple data and install packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Toy data:\n",
      "df1=\n",
      "                  name\n",
      "0             ABC Inc.\n",
      "1              abc inc\n",
      "2  A.B.C. INCORPORATED\n",
      "3      The XYZ Company\n",
      "4             X Y Z CO\n",
      "df2=\n",
      "       name\n",
      "0  ABC Inc.\n",
      "1   XYZ Co.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from nama import Matcher\n",
    "\n",
    "df1 = pd.DataFrame(['ABC Inc.','abc inc','A.B.C. INCORPORATED','The XYZ Company','X Y Z CO'],columns=['name'])\n",
    "df2 = pd.DataFrame(['ABC Inc.','XYZ Co.'],columns=['name'])\n",
    "\n",
    "print(f'Toy data:\\ndf1=\\n{df1}\\ndf2=\\n{df2}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nama is built around an object called a `Matcher`, which holds matching information about a set of strings and partitions the strings into non-overlapping groups.\n",
    "   - Strings in the same group are considered \"matched\"\n",
    "   - Strings in different groups are not matched.\n",
    "Nama provides tools for creating, modifying, saving, and loading matchers. Then matchers can be used to generate unique group ids for a set of strings, or perform two-way merges between pandas dataframes according to the match groups."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial string groups:\n",
      "{'ABC Inc.': ['ABC Inc.'], 'abc inc': ['abc inc'], 'A.B.C. INCORPORATED': ['A.B.C. INCORPORATED'], 'The XYZ Company': ['The XYZ Company'], 'X Y Z CO': ['X Y Z CO'], 'XYZ Co.': ['XYZ Co.']}\n",
      "Exact matching with singleton groups:\n",
      "     name_x match_group    name_y\n",
      "0  ABC Inc.    ABC Inc.  ABC Inc.\n",
      "Updated string groups:\n",
      "{'ABC Inc.': ['ABC Inc.'], 'abc inc': ['abc inc'], 'A.B.C. INCORPORATED': ['A.B.C. INCORPORATED'], 'The XYZ Company': ['The XYZ Company'], 'X Y Z CO': ['X Y Z CO', 'XYZ Co.']}\n",
      "X Y Z CO\n",
      "['X Y Z CO', 'XYZ Co.']\n",
      "                string  count                group\n",
      "0             ABC Inc.      2             ABC Inc.\n",
      "1             X Y Z CO      1             X Y Z CO\n",
      "2              XYZ Co.      1             X Y Z CO\n",
      "3  A.B.C. INCORPORATED      1  A.B.C. INCORPORATED\n",
      "4      The XYZ Company      1      The XYZ Company\n",
      "5              abc inc      1              abc inc\n"
     ]
    }
   ],
   "source": [
    "# We start matching by creating an empty matcher\n",
    "matcher = Matcher()\n",
    "\n",
    "# First we need to add all the strings we want to match to the matcher\n",
    "# (in this case the strings the name column of each dataframe)\n",
    "matcher = matcher.add_strings(df1['name'])\n",
    "matcher = matcher.add_strings(df2['name'])\n",
    "\n",
    "# Initially, strings are automatically assigned to singleton groups\n",
    "# (Groups are automatically labelled according to the most common string,\n",
    "# with ties broken alphabetically)\n",
    "print(f'Initial string groups:\\n{matcher.groups}')\n",
    "\n",
    "# At this point we can merge on exact matches, but there isn't much point\n",
    "# (equivalent to pandas merge function)\n",
    "print(f\"Exact matching with singleton groups:\\n{matcher.merge_dfs(df1,df2,on='name')}\")\n",
    "\n",
    "# To get better results, we need to modify the matcher.\n",
    "# Unite merges all groups that contain the passed strings.\n",
    "matcher = matcher.unite(['X Y Z CO','XYZ Co.'])\n",
    "print(f'Updated string groups:\\n{matcher.groups}')\n",
    "\n",
    "# We can inspect the united groups in 3 ways. \n",
    "# First, we can get the group that any string belongs too with\n",
    "print(matcher['XYZ Co.'])\n",
    "# We can inspect the all the strings in the same group (i.e. that match) with\n",
    "print(matcher.matches('XYZ Co.'))\n",
    "# Lastly we can convert the matcher to a dataframe\n",
    "print(matcher.to_df())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`unite` is very flexible. We can pass a single set of strings, a nested list of strings, or mapping from strings to group labels. The mapping can even be a function that evaluates strings and generates a label.This makes it very simple to do hash collision matching.\n",
    "\n",
    "Hash collision matching works by matching any strings that have the same hash. A hash could be almost anything, but one useful way to do collision matching is to match strings that are identical after simplifying both strings.\n",
    "\n",
    "Nama provides some useful simplification functions in nama.utils. `simplify_corp` strips punctuation and capitalization, and removes common parts of names like starting with \"the\", or ending with \"inc\" or \"ltd\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Groups after uniting by simplify_corp:\n",
      "{'A.B.C. INCORPORATED': ['A.B.C. INCORPORATED', 'ABC Inc.', 'abc inc'], 'The XYZ Company': ['The XYZ Company', 'XYZ Co.'], 'X Y Z CO': ['X Y Z CO']}\n"
     ]
    }
   ],
   "source": [
    "from nama.utils import simplify_corp\n",
    "\n",
    "# Make a new matcher for comparison\n",
    "corp_matcher = Matcher(matcher.strings())\n",
    "\n",
    "# Unite strings with the same simplified representation\n",
    "corp_matcher = corp_matcher.unite(simplify_corp)\n",
    "\n",
    "print(f'Groups after uniting by simplify_corp:\\n{corp_matcher.groups}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another useful approach to matching is to construct a similarity measure between strings. The standard way to do this is to break strings into \"tokens\"(words or short substrings) and use a measure like a weighted jaccard similarity index to summarize the overlap between the tokens in pairs ofstrings. The token_similarity module provides tools for matching based on token similarity.\n",
    "\n",
    "First, create a TokenSimilarity model. This can be customized with different tokenizers, similarity measures, and token weighting methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nama.similarity import TokenSimilarity\n",
    "\n",
    "token_model = TokenSimilarity()\n",
    "\n",
    "# In the future: A training set can be used to automatically pick the optimal similarity threshold for uniting strings.\n",
    "# For now: Just set the threshold manually.\n",
    "\n",
    "# Then we can use the similarity model to predict matches between the matcher\n",
    "# strings. The predict method returns a new matcher.\n",
    "token_matcher = token_model.predict(matcher.strings(), threshold=0.05)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Notice that the combination of the two matchers correctly groups all the strings. It is often useful to combine multiple matching techniques.\n",
    "\n",
    "We can integrate the corp and token matchers into the original matcher with unite."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matcher = matcher.unite(corp_matcher)\n",
    "matcher = matcher.unite(token_matcher)\n",
    "\n",
    "# Now merging the dataframes gives us the desired output\n",
    "print(f\"Merging with the final matcher:\\n{matcher.merge_dfs(df1,df2,on='name')}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also use the Embedding Similarity model to predict the similarity of larger and more complex "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nama.utils import load_similarity_model\n",
    "\n",
    "# First we'll need to load a model \n",
    "# From file\n",
    "sim = load_similarity_model(\"path-to-model.bin\")\n",
    "\n",
    "# Or we can use our standard model from huggingface\n",
    "# .... TBD\n",
    "\n",
    "# Then we'll have the model embed our matcher\n",
    "embeddings = sim.embed(matcher)\n",
    "\n",
    "# Now we can do some matching\n",
    "# We can unite strings according to their predicted pairwise similarity\n",
    "sim_matcher_similar = embeddings.unite_similar(threshold=0.5)\n",
    "\n",
    "# We can unite strings with each string's most similar target string\n",
    "# This method requires a set of target strings which will be matched to our embedded strings\n",
    "sim_matcher_nearest = embeddings.unite_nearest(target_strings=corp_matcher,threshold=0)\n",
    "\n",
    "# We can also manipulate the embeddings by slicing like so\n",
    "first_string = embeddings[0]\n",
    "#...\n",
    "\n",
    "# Lastly we can save the embeddings for later use\n",
    "embeddings.save(\"path-to-save-embeddings.bin\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also train an Embedding Similarity Model to predict the similarity of larger and more complex groupings for which we have some target values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nama.similarity import EmbeddingSimilarity\n",
    "\n",
    "train_kwargs = {\n",
    "    'max_epochs': 2,\n",
    "    'warmup_frac': 0.2,\n",
    "    'transformer_lr':1e-5,\n",
    "    'score_lr':10,\n",
    "    'batch_size':8,\n",
    "}\n",
    "\n",
    "sim = EmbeddingSimilarity()\n",
    "\n",
    "history_df = sim.train(matcher, verbose=True, **train_kwargs)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With a trained model we can run some tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can test the similarity model with a single threshold\n",
    "test_scores = sim.test(matcher, threshold=0.5)\n",
    "\n",
    "# Or can also run a test over multiple thresholds to find the optimal one\n",
    "test_scores = sim.test(matcher, threshold=np.linspace(0,1,20))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can then save our model to file for later use\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim.save(\"path-to-model.bin\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The matcher can also be converted to a dataframe if we want to cluster the names in one dataset or create a mapping to string groups that can be used accross multiple datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matcher_df = matcher.to_df()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we can save the matcher in csv format for later use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matcher.to_csv('matcher.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nama import read_csv\n",
    "\n",
    "# ...and load it again at a later time\n",
    "loaded_matcher = read_csv('matcher.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
