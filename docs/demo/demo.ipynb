{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NAMA Demo"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First lets create some simple data and install packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ben/.pyenv/versions/3.9.7/envs/nama5/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Toy data:\n",
      "df1=\n",
      "                  name\n",
      "0             ABC Inc.\n",
      "1              abc inc\n",
      "2  A.B.C. INCORPORATED\n",
      "3      The XYZ Company\n",
      "4             X Y Z CO\n",
      "df2=\n",
      "       name\n",
      "0  ABC Inc.\n",
      "1   XYZ Co.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from nama import MatchData\n",
    "\n",
    "df1 = pd.DataFrame(['ABC Inc.','abc inc','A.B.C. INCORPORATED','The XYZ Company','X Y Z CO'],columns=['name'])\n",
    "df2 = pd.DataFrame(['ABC Inc.','XYZ Co.'],columns=['name'])\n",
    "\n",
    "print(f'Toy data:\\ndf1=\\n{df1}\\ndf2=\\n{df2}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Match Data\n",
    "\n",
    "Nama is built around an object called `Match Data`, which holds matching information about a set of strings and partitions the strings into non-overlapping groups.\n",
    "   - Strings in the same group are considered \"matched\"\n",
    "   - Strings in different groups are not matched.\n",
    "Nama provides tools for creating, modifying, saving, and loading matches. Then these matches can be used to generate unique group ids for a set of strings, or perform two-way merges between pandas dataframes according to the match groups."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial string groups:\n",
      "{'ABC Inc.': ['ABC Inc.'], 'abc inc': ['abc inc'], 'A.B.C. INCORPORATED': ['A.B.C. INCORPORATED'], 'The XYZ Company': ['The XYZ Company'], 'X Y Z CO': ['X Y Z CO'], 'XYZ Co.': ['XYZ Co.']}\n"
     ]
    }
   ],
   "source": [
    "# We start matching by creating an empty matches\n",
    "matches = MatchData()\n",
    "\n",
    "# First we need to add all the strings we want to match to the matches\n",
    "# (in this case the strings the name column of each dataframe)\n",
    "matches = matches.add_strings(df1['name'])\n",
    "matches = matches.add_strings(df2['name'])\n",
    "\n",
    "# Initially, strings are automatically assigned to singleton groups\n",
    "# (Groups are automatically labelled according to the most common string,\n",
    "# with ties broken alphabetically)\n",
    "print(f'Initial string groups:\\n{matches.groups}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exact matching with singleton groups:\n",
      "     name_x match_group    name_y\n",
      "0  ABC Inc.    ABC Inc.  ABC Inc.\n"
     ]
    }
   ],
   "source": [
    "# At this point we can merge on exact matches, but there isn't much point\n",
    "# (equivalent to pandas merge function)\n",
    "print(f\"Exact matching with singleton groups:\\n{matches.merge_dfs(df1,df2,on='name')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated string groups:\n",
      "{'ABC Inc.': ['ABC Inc.', 'A.B.C. INCORPORATED'], 'abc inc': ['abc inc'], 'The XYZ Company': ['The XYZ Company'], 'X Y Z CO': ['X Y Z CO'], 'XYZ Co.': ['XYZ Co.']}\n"
     ]
    }
   ],
   "source": [
    "# To get better results, we need to modify the matches.\n",
    "# Unite merges all groups that contain the passed strings.\n",
    "matches = matches.unite(['ABC Inc.', 'A.B.C. INCORPORATED'])\n",
    "print(f'Updated string groups:\\n{matches.groups}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`unite` is very flexible. We can pass a single set of strings, a nested list of strings, or mapping from strings to group labels. The mapping can even be a function that evaluates strings and generates a label.This makes it very simple to do hash collision matching.\n",
    "\n",
    "Hash collision matching works by matching any strings that have the same hash. A hash could be almost anything, but one useful way to do collision matching is to match strings that are identical after simplifying both strings.\n",
    "\n",
    "Nama provides some useful simplification functions in nama.utils. `simplify_corp` strips punctuation and capitalization, and removes common parts of names like starting with \"the\", or ending with \"inc\" or \"ltd\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Groups after uniting by simplify_corp:\n",
      "{'A.B.C. INCORPORATED': ['A.B.C. INCORPORATED', 'abc inc', 'ABC Inc.'], 'The XYZ Company': ['The XYZ Company', 'XYZ Co.'], 'X Y Z CO': ['X Y Z CO']}\n"
     ]
    }
   ],
   "source": [
    "from nama import simplify_corp\n",
    "\n",
    "# Make a new matches for comparison\n",
    "corp_matches = MatchData(matches.strings())\n",
    "\n",
    "# Unite strings with the same simplified representation\n",
    "corp_matches = corp_matches.unite(simplify_corp)\n",
    "\n",
    "print(f'Groups after uniting by simplify_corp:\\n{corp_matches.groups}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also inspect the united groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ABC Inc.\n",
      "['ABC Inc.', 'A.B.C. INCORPORATED']\n",
      "                string  count            group\n",
      "0             ABC Inc.      2         ABC Inc.\n",
      "1  A.B.C. INCORPORATED      1         ABC Inc.\n",
      "2      The XYZ Company      1  The XYZ Company\n",
      "3             X Y Z CO      1         X Y Z CO\n",
      "4              XYZ Co.      1          XYZ Co.\n",
      "5              abc inc      1          abc inc\n"
     ]
    }
   ],
   "source": [
    "# Firstly, we can get the group that any string belongs too with\n",
    "print(matches['A.B.C. INCORPORATED'])\n",
    "# We can inspect the all the strings in the same group (i.e. that match) with\n",
    "print(matches.matches('A.B.C. INCORPORATED'))\n",
    "# Lastly we can convert the matches to a dataframe\n",
    "print(matches.to_df())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The matches can also be converted to a dataframe if we want to cluster the names in one dataset or create a mapping to string groups that can be used accross multiple datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>string</th>\n",
       "      <th>count</th>\n",
       "      <th>group</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ABC Inc.</td>\n",
       "      <td>2</td>\n",
       "      <td>ABC Inc.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A.B.C. INCORPORATED</td>\n",
       "      <td>1</td>\n",
       "      <td>ABC Inc.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The XYZ Company</td>\n",
       "      <td>1</td>\n",
       "      <td>The XYZ Company</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>X Y Z CO</td>\n",
       "      <td>1</td>\n",
       "      <td>X Y Z CO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>XYZ Co.</td>\n",
       "      <td>1</td>\n",
       "      <td>XYZ Co.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>abc inc</td>\n",
       "      <td>1</td>\n",
       "      <td>abc inc</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                string  count            group\n",
       "0             ABC Inc.      2         ABC Inc.\n",
       "1  A.B.C. INCORPORATED      1         ABC Inc.\n",
       "2      The XYZ Company      1  The XYZ Company\n",
       "3             X Y Z CO      1         X Y Z CO\n",
       "4              XYZ Co.      1          XYZ Co.\n",
       "5              abc inc      1          abc inc"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matches_df = matches.to_df()\n",
    "matches_df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we can save the matches in csv format for later use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "matches.to_csv('matches.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>string</th>\n",
       "      <th>count</th>\n",
       "      <th>group</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ABC Inc.</td>\n",
       "      <td>2</td>\n",
       "      <td>ABC Inc.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A.B.C. INCORPORATED</td>\n",
       "      <td>1</td>\n",
       "      <td>ABC Inc.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The XYZ Company</td>\n",
       "      <td>1</td>\n",
       "      <td>The XYZ Company</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>X Y Z CO</td>\n",
       "      <td>1</td>\n",
       "      <td>X Y Z CO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>XYZ Co.</td>\n",
       "      <td>1</td>\n",
       "      <td>XYZ Co.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>abc inc</td>\n",
       "      <td>1</td>\n",
       "      <td>abc inc</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                string  count            group\n",
       "0             ABC Inc.      2         ABC Inc.\n",
       "1  A.B.C. INCORPORATED      1         ABC Inc.\n",
       "2      The XYZ Company      1  The XYZ Company\n",
       "3             X Y Z CO      1         X Y Z CO\n",
       "4              XYZ Co.      1          XYZ Co.\n",
       "5              abc inc      1          abc inc"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nama import read_csv\n",
    "\n",
    "# ...and load it again at a later time\n",
    "loaded_matches = read_csv('matches.csv')\n",
    "loaded_matches.to_df()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Embedding Similarity\n",
    "\n",
    "The Embedding Similarity model allows us to predict the similarity of larger and more complex strings"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we'll need to train a Similarity Model to predict the similarity of larger and more complex matches for which we have some target values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training epoch 0: 100%|██████████| 1/1 [00:09<00:00,  9.70s/it]\n",
      "training epoch 1: 100%|██████████| 1/1 [00:06<00:00,  6.76s/it]\n"
     ]
    }
   ],
   "source": [
    "from nama import SimilarityModel\n",
    "\n",
    "train_kwargs = {\n",
    "    'max_epochs': 2,\n",
    "    'warmup_frac': 0.2,\n",
    "    'transformer_lr':1e-5,\n",
    "    'score_lr':10,\n",
    "    'batch_size':8,\n",
    "}\n",
    "\n",
    "sim = SimilarityModel()\n",
    "\n",
    "history_df = sim.train(matches, verbose=True, **train_kwargs)\n",
    "\n",
    "# Save our trained model to disk\n",
    "sim.save(\"path-to-model.bin\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Embeddings Model has some powerful function that allow us to unite strings in various ways. \n",
    "\n",
    "The `unite_similar` function allow us to match similar strings based on their predicted pairwise similarity. \n",
    "\n",
    "The `unite_nearest` function allow us to uniting embedding strings with their most similar target strings. This function is particularly useful in scenarios where you have a set of target strings and want to match each embedding string to its nearest corresponding target string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding shape:  torch.Size([1, 128])\n"
     ]
    }
   ],
   "source": [
    "from nama import load_similarity_model\n",
    "\n",
    "# We can use our train model directly or load it from the save file\n",
    "sim = load_similarity_model(\"path-to-model.bin\")\n",
    "\n",
    "# Or we can use the standard model from huggingface\n",
    "# .... TBD\n",
    "\n",
    "# Then we'll have the model embed our matches\n",
    "embeddings = sim.embed(matches)\n",
    "\n",
    "# Now we can do some matching\n",
    "# We can unite strings according to their predicted pairwise similarity\n",
    "sim_matches_similar = embeddings.unite_similar(threshold=0.5)\n",
    "\n",
    "# We can unite strings with each string's most similar target string\n",
    "# This method requires a set of target strings which will be matched to our embedded strings\n",
    "sim_matches_nearest = embeddings.unite_nearest(target_strings=corp_matches.strings(),threshold=0)\n",
    "\n",
    "# We can also manipulate the embeddings by slicing like so\n",
    "first_embedding = embeddings[0:1]\n",
    "print(\"Embedding shape: \", first_embedding.V.shape)\n",
    "\n",
    "# Lastly we can save the embeddings for later use\n",
    "embeddings.save(\"path-to-save-embeddings.bin\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With a trained model we can run some tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TP</th>\n",
       "      <th>FP</th>\n",
       "      <th>TN</th>\n",
       "      <th>FN</th>\n",
       "      <th>coverage</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.181818</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   TP  FP  TN  FN  coverage  accuracy  precision  recall        F1\n",
       "0   2  18   0   0       1.0       0.1        0.1     1.0  0.181818"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We can test the similarity model with a single threshold\n",
    "test_scores = sim.test(matches, threshold=0.5)\n",
    "pd.DataFrame([test_scores])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TP</th>\n",
       "      <th>FP</th>\n",
       "      <th>TN</th>\n",
       "      <th>FN</th>\n",
       "      <th>coverage</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>threshold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>0.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>0.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    TP  FP  TN  FN  coverage  accuracy  precision  recall        F1  threshold\n",
       "0    2  18   0   0       1.0       0.1        0.1     1.0  0.181818        0.0\n",
       "1    2  18   0   0       1.0       0.1        0.1     1.0  0.181818        0.1\n",
       "2    2  18   0   0       1.0       0.1        0.1     1.0  0.181818        0.2\n",
       "3    2  18   0   0       1.0       0.1        0.1     1.0  0.181818        0.3\n",
       "4    2  18   0   0       1.0       0.1        0.1     1.0  0.181818        0.4\n",
       "5    2  18   0   0       1.0       0.1        0.1     1.0  0.181818        0.5\n",
       "6    2  18   0   0       1.0       0.1        0.1     1.0  0.181818        0.6\n",
       "7    2  18   0   0       1.0       0.1        0.1     1.0  0.181818        0.7\n",
       "8    2  18   0   0       1.0       0.1        0.1     1.0  0.181818        0.8\n",
       "9    0   6  12   2       1.0       0.0        0.0     0.0  0.000000        0.9\n",
       "10   0   0  18   2       1.0       0.0        0.0     0.0  0.000000        1.0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Or can also run a test over multiple thresholds to find the optimal one\n",
    "test_scores = sim.test(matches, threshold=np.linspace(0,1,11))\n",
    "pd.DataFrame(test_scores)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
